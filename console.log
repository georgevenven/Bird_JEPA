starting inference mode, logging to console.log
loading model checkpoint from experiments/BirdJEPA_Small_Finetune/weights/best_loss_step_2750.pt
Loading pretrained encoder from experiments/BirdJEPA_Small_Untrained
Conv layer conv1: 320 parameters
Conv layer conv2: 25632 parameters
Conv layer conv3: 50208 parameters
Conv layer conv4: 50208 parameters
Total convolutional parameters: 126368
Local attention block 0: 83008 parameters, each token attends to 17 tokens
Total attention connections in block 0: 17000
Global attention block 1: 83008 parameters, 10 tokens with global attention
Total attention connections in block 1: 10990
Local attention block 2: 83008 parameters, each token attends to 33 tokens
Total attention connections in block 2: 33000
Global attention block 3: 83008 parameters, 20 tokens with global attention
Total attention connections in block 3: 20980
Local attention block 4: 83008 parameters, each token attends to 33 tokens
Total attention connections in block 4: 33000
Global attention block 5: 83008 parameters, 20 tokens with global attention
Total attention connections in block 5: 20980
Total transformer parameters: 498048
Total attention connections across all blocks: 135950
Total model parameters: 1554753

Loaded checkpoint details:
Path: experiments/BirdJEPA_Small_Untrained/saved_weights/checkpoint_0.pt
Training step: 0
Encoder optimizer state included: Yes
Predictor optimizer state included: Yes
Decoder optimizer state included: Yes
Model initialized with context_length=1000, num_classes=206, pooling=mean
loading checkpoint for ONNX export
