{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 73])\n",
      "torch.Size([73])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "pt_file = \"/media/george-vengrovski/Desk SSD/BirdJEPA/llb3_val/llb3_0001_2018_04_23_14_18_03.pt\"\n",
    "data = torch.load(pt_file)\n",
    "print(data['s'].shape)\n",
    "print(data['labels'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_dataset_default_config_name' from 'datasets.inspect' (/home/george-vengrovski/anaconda3/envs/tweetybert/lib/python3.11/site-packages/datasets/inspect.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# reload datasets in case the wheel was just upgraded in-process\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m reload(datasets)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# sanity check\u001b[39;00m\n\u001b[1;32m     18\u001b[0m req_ver \u001b[38;5;241m=\u001b[39m pkg_resources\u001b[38;5;241m.\u001b[39mparse_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.18.0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tweetybert/lib/python3.11/importlib/__init__.py:169\u001b[0m, in \u001b[0;36mreload\u001b[0;34m(module)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspec not found for the module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m--> 169\u001b[0m _bootstrap\u001b[38;5;241m.\u001b[39m_exec(spec, module)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The module may have replaced itself in sys.modules!\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules[name]\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:621\u001b[0m, in \u001b[0;36m_exec\u001b[0;34m(spec, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:940\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/tweetybert/lib/python3.11/site-packages/datasets/__init__.py:26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfingerprint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m disable_caching, enable_caching, is_caching_enabled\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetInfo\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspect\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     get_dataset_config_info,\n\u001b[1;32m     28\u001b[0m     get_dataset_config_names,\n\u001b[1;32m     29\u001b[0m     get_dataset_default_config_name,\n\u001b[1;32m     30\u001b[0m     get_dataset_infos,\n\u001b[1;32m     31\u001b[0m     get_dataset_split_names,\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miterable_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IterableDataset\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset, load_dataset_builder, load_from_disk\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_dataset_default_config_name' from 'datasets.inspect' (/home/george-vengrovski/anaconda3/envs/tweetybert/lib/python3.11/site-packages/datasets/inspect.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# %% birdset notebook cell (version-safe)\n",
    "# ---------------------------------------------------------------------------\n",
    "# pull BirdSet subsets straight into a local HF cache on your HDD\n",
    "# tweak the variables below → run once per notebook session\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# 1) make sure the datasets wheel is new enough for `trust_remote_code`\n",
    "!pip install -q --upgrade \"datasets[audio]>=2.18.0\" soundfile\n",
    "\n",
    "from importlib import reload\n",
    "import datasets, pkg_resources, sys, subprocess, os\n",
    "from pathlib import Path\n",
    "\n",
    "# reload datasets in case the wheel was just upgraded in-process\n",
    "reload(datasets)\n",
    "\n",
    "# sanity check\n",
    "req_ver = pkg_resources.parse_version(\"2.18.0\")\n",
    "cur_ver = pkg_resources.parse_version(datasets.__version__)\n",
    "if cur_ver < req_ver:\n",
    "    raise RuntimeError(\n",
    "        f\"datasets {cur_ver} is too old; restart the kernel or upgrade manually to >= {req_ver}\"\n",
    "    )\n",
    "\n",
    "# ─── user-tunable knobs ─────────────────────────────────────────────────────\n",
    "CACHE_DIR = Path(\"/media/george-vengrovski/Desk SSD/BirdSet\")   # ⚠️ needs ~1 TB for XCL\n",
    "CONFIGS   = [\"XCL\"]                        # e.g. [\"HSN\", \"PER_xc\", \"XCL\"]\n",
    "SPLITS    = None                           # None → materialise all splits\n",
    "NUM_PROC  = 8                              # parallel unzip/hash workers\n",
    "STREAMING = False                          # True → just metadata, no audio\n",
    "# ────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = str(CACHE_DIR.resolve())\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "def materialise(ds, splits):\n",
    "    \"\"\"iterate once so the audio actually hits disk (no-op if streaming=True).\"\"\"\n",
    "    for split in (splits or ds.keys()):\n",
    "        for _ in ds[split]:\n",
    "            pass\n",
    "\n",
    "for cfg in CONFIGS:\n",
    "    print(f\"⇢ downloading BirdSet[{cfg}] to {CACHE_DIR} ...\", flush=True)\n",
    "    ds = load_dataset(\n",
    "        \"DBD-research-group/BirdSet\",\n",
    "        cfg,\n",
    "        trust_remote_code=True,\n",
    "        cache_dir=CACHE_DIR,\n",
    "        num_proc=None if STREAMING else NUM_PROC,\n",
    "        streaming=STREAMING,\n",
    "    )\n",
    "    if STREAMING:\n",
    "        print(\"   • streaming mode: only metadata cached\\n\")\n",
    "    else:\n",
    "        materialise(ds, SPLITS)\n",
    "        print(\"   ✓ finished materialising audio\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweetybert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
